{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "054e2e26",
   "metadata": {},
   "source": [
    "# This is a notebook for classification according to Wolfram.\n",
    "## Purpose\n",
    "\n",
    "Classify 88 ECA rules into Wolfram's four classes using **Random Forest**.\n",
    "\n",
    "## Method\n",
    "\n",
    "- Extract 10 features: λ, Shannon entropy, LZ complexity, Hamming distance (mean/std), spreading rate, time to stability, activity, periodicity score, chaos indicator\n",
    "- Direct 4-class classification (Class I/II/III/IV) using Random Forest\n",
    "- 5-fold cross-validation\n",
    "\n",
    "## Use Case\n",
    "\n",
    "For quick, straightforward classification that directly outputs predicted class for each rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e08ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import os\n",
    "\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "wolfram_labels = {\n",
    "    0: 'I', 8: 'I', 32: 'I', 40: 'I', 128: 'I', 136: 'I', 160: 'I', 168: 'I',\n",
    "    1: 'II', 2: 'II', 3: 'II', 4: 'II', 5: 'II', 6: 'II', 7: 'II', 9: 'II',\n",
    "    10: 'II', 11: 'II', 12: 'II', 13: 'II', 14: 'II', 15: 'II', 19: 'II', 23: 'II',\n",
    "    24: 'II', 25: 'II', 26: 'II', 27: 'II', 28: 'II', 29: 'II', 33: 'II', 34: 'II',\n",
    "    35: 'II', 36: 'II', 37: 'II', 38: 'II', 42: 'II', 43: 'II', 44: 'II', 46: 'II',\n",
    "    50: 'II', 51: 'II', 56: 'II', 57: 'II', 58: 'II', 62: 'II', 72: 'II', 73: 'II',\n",
    "    74: 'II', 76: 'II', 77: 'II', 78: 'II', 94: 'II', 104: 'II', 108: 'II',\n",
    "    130: 'II', 132: 'II', 134: 'II', 138: 'II', 140: 'II', 142: 'II', 152: 'II',\n",
    "    154: 'II', 156: 'II', 162: 'II', 164: 'II', 170: 'II', 172: 'II', 178: 'II',\n",
    "    184: 'II', 200: 'II', 204: 'II', 232: 'II',\n",
    "    18: 'III', 22: 'III', 30: 'III', 45: 'III', 60: 'III', 90: 'III', 105: 'III',\n",
    "    122: 'III', 126: 'III', 146: 'III', 150: 'III',\n",
    "    41: 'IV', 54: 'IV', 106: 'IV', 110: 'IV'\n",
    "}\n",
    "\n",
    "CLASS_MAP = {'I': 0, 'II': 1, 'III': 2, 'IV': 3}\n",
    "\n",
    "# you can use these default values or change them as needed\n",
    "N_STEPS = 1000\n",
    "N_CELLS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c2002d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ ECA Evolution Function ------ ###\n",
    "\"\"\"\n",
    "In here, you input the rule, steps and cells you want to evolve.\n",
    "\"\"\"\n",
    "def evolve_eca(rule, n_steps=N_STEPS, n_cells=N_CELLS):\n",
    "    rule_binary = format(rule, '08b')[::-1]\n",
    "    lookup = np.array([int(rule_binary[i]) for i in range(8)], dtype=np.int8)\n",
    "    \n",
    "    current = np.zeros(n_cells, dtype=np.int8)\n",
    "    current[n_cells//2] = 1\n",
    "    space_time = np.zeros((n_steps, n_cells), dtype=np.int8)\n",
    "    space_time[0] = current\n",
    "    \n",
    "    for t in range(1, n_steps):\n",
    "        left = np.roll(current, 1)\n",
    "        right = np.roll(current, -1)\n",
    "        neighborhood = left * 4 + current * 2 + right\n",
    "        current = lookup[neighborhood]\n",
    "        space_time[t] = current\n",
    "    \n",
    "    return space_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "307c28b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ Feature Extraction ------ ###\n",
    "def lempel_ziv_complexity(sequence):\n",
    "    s = ''.join(map(str, sequence.flatten()))\n",
    "    n = len(s)\n",
    "    i, k, l = 0, 1, 1\n",
    "    c, k_max = 1, 1\n",
    "    \n",
    "    while i + k <= n:\n",
    "        temp = s[i:i+k]\n",
    "        if i > 0 and temp in s[i-l:i+k-1]:\n",
    "            k += 1\n",
    "        else:\n",
    "            c += 1\n",
    "            i += k\n",
    "            k = 1\n",
    "            k_max = max(k_max, i+k-l)\n",
    "            l = k_max\n",
    "    \n",
    "    return c / (n / np.log2(n + 1e-10))\n",
    "\n",
    "def extract_features(space_time):\n",
    "    n_steps, n_cells = space_time.shape\n",
    "    features = {}\n",
    "    \n",
    "    rule_density = np.mean(space_time)\n",
    "    features['lambda'] = rule_density\n",
    "    \n",
    "    flat = space_time.flatten()\n",
    "    p = np.bincount(flat, minlength=2) / len(flat)\n",
    "    features['shannon_entropy'] = -np.sum(p * np.log2(p + 1e-10))\n",
    "    \n",
    "    features['lz_complexity'] = lempel_ziv_complexity(space_time)\n",
    "    \n",
    "    hamming_distances = [np.sum(space_time[t] != space_time[t-1]) / n_cells \n",
    "                        for t in range(1, n_steps)]\n",
    "    features['hamming_mean'] = np.mean(hamming_distances)\n",
    "    features['hamming_std'] = np.std(hamming_distances)\n",
    "    \n",
    "    active_widths = []\n",
    "    for t in range(n_steps):\n",
    "        if np.any(space_time[t] == 1):\n",
    "            active_indices = np.where(space_time[t] == 1)[0]\n",
    "            active_widths.append(active_indices[-1] - active_indices[0])\n",
    "    features['spreading_rate'] = np.polyfit(range(len(active_widths)), \n",
    "                                            active_widths, 1)[0] if len(active_widths) > 10 else 0\n",
    "    \n",
    "    stability_threshold = 0.05\n",
    "    stable_time = n_steps\n",
    "    for t in range(10, n_steps):\n",
    "        recent_changes = [np.sum(space_time[t-i] != space_time[t-i-1]) / n_cells \n",
    "                         for i in range(min(10, t))]\n",
    "        if np.mean(recent_changes) < stability_threshold:\n",
    "            stable_time = t\n",
    "            break\n",
    "    features['time_to_stability'] = stable_time / n_steps\n",
    "    \n",
    "    features['activity'] = rule_density\n",
    "    \n",
    "    fft_peaks = []\n",
    "    for col in range(min(10, n_cells)):\n",
    "        if np.std(space_time[:, col]) > 0:\n",
    "            fft = np.abs(np.fft.rfft(space_time[:, col]))\n",
    "            peaks, _ = signal.find_peaks(fft, height=np.max(fft)*0.1)\n",
    "            fft_peaks.append(len(peaks))\n",
    "    features['periodicity_score'] = np.mean(fft_peaks) if fft_peaks else 0\n",
    "    \n",
    "    change_rates = [np.sum(space_time[t] != space_time[t-1]) / n_cells \n",
    "                   for t in range(1, n_steps)]\n",
    "    features['chaos_indicator'] = np.std(change_rates)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8364d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ Batch Processing ------ ###\n",
    "def extract_all_features(rules):\n",
    "    all_features = []\n",
    "    computation_times = []\n",
    "    \n",
    "    for rule in rules:\n",
    "        start_time = time.time()\n",
    "        space_time = evolve_eca(rule)\n",
    "        features = extract_features(space_time)\n",
    "        features['rule'] = rule\n",
    "        features['known_class'] = wolfram_labels[rule]\n",
    "        all_features.append(features)\n",
    "        computation_times.append(time.time() - start_time)\n",
    "    \n",
    "    df = pd.DataFrame(all_features)\n",
    "    df['computation_time'] = computation_times\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c545562",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------ Classification ------ ###\n",
    "def classify_rules(df):\n",
    "    feature_cols = ['lambda', 'shannon_entropy', 'lz_complexity', 'hamming_mean', \n",
    "                   'hamming_std', 'spreading_rate', 'time_to_stability', \n",
    "                   'activity', 'periodicity_score', 'chaos_indicator']\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df['known_class'].map(CLASS_MAP).values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', \n",
    "                                 random_state=726, max_depth=10)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    predictions = np.zeros(len(y))\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X_scaled, y):\n",
    "        clf.fit(X_scaled[train_idx], y[train_idx])\n",
    "        predictions[test_idx] = clf.predict(X_scaled[test_idx])\n",
    "    \n",
    "    inv_map = {v: k for k, v in CLASS_MAP.items()}\n",
    "    df['predicted_class'] = [inv_map[int(p)] for p in predictions]\n",
    "\n",
    "    clf.fit(X_scaled, y)\n",
    "    \n",
    "    return df, clf, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94c08a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           I       0.67      1.00      0.80         8\n",
      "          II       0.90      0.85      0.87        65\n",
      "         III       0.47      0.64      0.54        11\n",
      "          IV       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.80        88\n",
      "   macro avg       0.51      0.62      0.55        88\n",
      "weighted avg       0.78      0.80      0.78        88\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "     I  II  III  IV\n",
      "I    8   0    0   0\n",
      "II   4  55    6   0\n",
      "III  0   4    7   0\n",
      "IV   0   2    2   0\n",
      "\n",
      "Total computation time: 326.22s\n",
      "Average time per rule: 3.707s\n",
      "\n",
      "Feature Importance:\n",
      "             feature  importance\n",
      "2      lz_complexity    0.168594\n",
      "4        hamming_std    0.146499\n",
      "0             lambda    0.145697\n",
      "7           activity    0.118233\n",
      "9    chaos_indicator    0.112232\n",
      "1    shannon_entropy    0.109378\n",
      "3       hamming_mean    0.092671\n",
      "5     spreading_rate    0.056713\n",
      "8  periodicity_score    0.031081\n",
      "6  time_to_stability    0.018901\n"
     ]
    }
   ],
   "source": [
    "### ------ Module 6: Results ------ ###\n",
    "def get_features_table(df):\n",
    "    feature_cols = ['rule', 'lambda', 'shannon_entropy', 'lz_complexity', \n",
    "                   'hamming_mean', 'hamming_std', 'spreading_rate', \n",
    "                   'time_to_stability', 'activity', 'periodicity_score', \n",
    "                   'chaos_indicator', 'predicted_class', 'known_class', \n",
    "                   'computation_time']\n",
    "    return df[feature_cols].copy()\n",
    "\n",
    "def get_feature_importance(model):\n",
    "    feature_names = ['lambda', 'shannon_entropy', 'lz_complexity', 'hamming_mean', \n",
    "                    'hamming_std', 'spreading_rate', 'time_to_stability', \n",
    "                    'activity', 'periodicity_score', 'chaos_indicator']\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    return importance_df\n",
    "\n",
    "def evaluate_classification(df):\n",
    "    y_true = df['known_class'].map(CLASS_MAP)\n",
    "    y_pred = df['predicted_class'].map(CLASS_MAP)\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, \n",
    "                                target_names=['I', 'II', 'III', 'IV']))\n",
    "    \n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=['I', 'II', 'III', 'IV'], \n",
    "                        columns=['I', 'II', 'III', 'IV'])\n",
    "    print(cm_df)\n",
    "    \n",
    "    print(f\"\\nTotal computation time: {df['computation_time'].sum():.2f}s\")\n",
    "    print(f\"Average time per rule: {df['computation_time'].mean():.3f}s\")\n",
    "\n",
    "### ------ Module 7: Execute ------ ###\n",
    "rules = list(wolfram_labels.keys())\n",
    "df_features = extract_all_features(rules)\n",
    "df_results, model, scaler = classify_rules(df_features)\n",
    "\n",
    "evaluate_classification(df_results)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(get_feature_importance(model))\n",
    "\n",
    "results_table = get_features_table(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0c0bb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rule</th>\n",
       "      <th>lambda</th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>lz_complexity</th>\n",
       "      <th>hamming_mean</th>\n",
       "      <th>hamming_std</th>\n",
       "      <th>spreading_rate</th>\n",
       "      <th>time_to_stability</th>\n",
       "      <th>activity</th>\n",
       "      <th>periodicity_score</th>\n",
       "      <th>chaos_indicator</th>\n",
       "      <th>predicted_class</th>\n",
       "      <th>known_class</th>\n",
       "      <th>computation_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>2.928539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>2.920619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>2.907211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>2.906524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.162276e-04</td>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "      <td>2.907486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>150</td>\n",
       "      <td>0.30832</td>\n",
       "      <td>0.891225</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.336937</td>\n",
       "      <td>1.347635e-01</td>\n",
       "      <td>0.013637</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30832</td>\n",
       "      <td>12.777778</td>\n",
       "      <td>1.347635e-01</td>\n",
       "      <td>III</td>\n",
       "      <td>III</td>\n",
       "      <td>1.051198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>41</td>\n",
       "      <td>0.49000</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.049829</td>\n",
       "      <td>0.970020</td>\n",
       "      <td>1.223721e-02</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.49000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.223721e-02</td>\n",
       "      <td>II</td>\n",
       "      <td>IV</td>\n",
       "      <td>2.090342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>54</td>\n",
       "      <td>0.48800</td>\n",
       "      <td>0.999584</td>\n",
       "      <td>0.013620</td>\n",
       "      <td>0.731972</td>\n",
       "      <td>2.624197e-01</td>\n",
       "      <td>0.014008</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48800</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>2.624197e-01</td>\n",
       "      <td>III</td>\n",
       "      <td>IV</td>\n",
       "      <td>3.372698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>106</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>0.080793</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>3.469447e-18</td>\n",
       "      <td>II</td>\n",
       "      <td>IV</td>\n",
       "      <td>5.259432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>110</td>\n",
       "      <td>0.54116</td>\n",
       "      <td>0.995106</td>\n",
       "      <td>0.374880</td>\n",
       "      <td>0.401211</td>\n",
       "      <td>7.822630e-02</td>\n",
       "      <td>0.021339</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.54116</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>7.822630e-02</td>\n",
       "      <td>III</td>\n",
       "      <td>IV</td>\n",
       "      <td>1.498071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    rule   lambda  shannon_entropy  lz_complexity  hamming_mean   hamming_std  \\\n",
       "0      0  0.00001         0.000181       0.000664      0.000010  3.162276e-04   \n",
       "1      8  0.00001         0.000181       0.000664      0.000010  3.162276e-04   \n",
       "2     32  0.00001         0.000181       0.000664      0.000010  3.162276e-04   \n",
       "3     40  0.00001         0.000181       0.000664      0.000010  3.162276e-04   \n",
       "4    128  0.00001         0.000181       0.000664      0.000010  3.162276e-04   \n",
       "..   ...      ...              ...            ...           ...           ...   \n",
       "83   150  0.30832         0.891225       0.386174      0.336937  1.347635e-01   \n",
       "84    41  0.49000         0.999711       0.049829      0.970020  1.223721e-02   \n",
       "85    54  0.48800         0.999584       0.013620      0.731972  2.624197e-01   \n",
       "86   106  0.01000         0.080793       0.001329      0.020000  3.469447e-18   \n",
       "87   110  0.54116         0.995106       0.374880      0.401211  7.822630e-02   \n",
       "\n",
       "    spreading_rate  time_to_stability  activity  periodicity_score  \\\n",
       "0         0.000000               0.01   0.00001           0.000000   \n",
       "1         0.000000               0.01   0.00001           0.000000   \n",
       "2         0.000000               0.01   0.00001           0.000000   \n",
       "3         0.000000               0.01   0.00001           0.000000   \n",
       "4         0.000000               0.01   0.00001           0.000000   \n",
       "..             ...                ...       ...                ...   \n",
       "83        0.013637               1.00   0.30832          12.777778   \n",
       "84        0.000306               1.00   0.49000           0.000000   \n",
       "85        0.014008               1.00   0.48800           0.500000   \n",
       "86        0.000000               0.01   0.01000          49.000000   \n",
       "87        0.021339               0.01   0.54116           2.900000   \n",
       "\n",
       "    chaos_indicator predicted_class known_class  computation_time  \n",
       "0      3.162276e-04               I           I          2.928539  \n",
       "1      3.162276e-04               I           I          2.920619  \n",
       "2      3.162276e-04               I           I          2.907211  \n",
       "3      3.162276e-04               I           I          2.906524  \n",
       "4      3.162276e-04               I           I          2.907486  \n",
       "..              ...             ...         ...               ...  \n",
       "83     1.347635e-01             III         III          1.051198  \n",
       "84     1.223721e-02              II          IV          2.090342  \n",
       "85     2.624197e-01             III          IV          3.372698  \n",
       "86     3.469447e-18              II          IV          5.259432  \n",
       "87     7.822630e-02             III          IV          1.498071  \n",
       "\n",
       "[88 rows x 14 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
